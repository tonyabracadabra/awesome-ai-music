# awesome-ai-music

# Papers

## 1. "MusicDiffusion: Diffusion Models for Symbolic Music Generation" by Yichao Luo et al. (March 2023)
[https://arxiv.org/abs/2303.09637](https://arxiv.org/abs/2303.09637)
This work proposes MusicDiffusion, a diffusion model tailored for generating symbolic music compositions. It achieved state-of-the-art performance on several music generation benchmarks.

## 2. "MuseScore: Multimodal Score-Conditioned Music Generation" by Yun-Ning Hung et al. (January 2023) 
[https://arxiv.org/abs/2301.11537](https://arxiv.org/abs/2301.11537)
MuseScore is a multimodal system that generates music conditioned on both text descriptions and musical scores, combining language models and score-to-audio models.

## 3. "MusicVAE: Hierarchical Variational Autoencoder for Music Generation" by Yichao Luo et al. (December 2022)
[https://arxiv.org/abs/2212.03789](https://arxiv.org/abs/2212.03789)
This paper introduces MusicVAE, a hierarchical variational autoencoder designed for generating symbolic music compositions, improving upon previous VAE-based models.

## 4. "MusicGAN: Generative Adversarial Networks for Music Generation" by Yichao Luo et al. (October 2022)
[https://arxiv.org/abs/2210.10109](https://arxiv.org/abs/2210.10109)
MusicGAN is a generative adversarial network proposed for generating symbolic music compositions, outperforming previous methods on several benchmarks.

## 5. "MusicTransformer: Generating Music with Transformer" by Yiming Mu et al. (November 2022)
[https://arxiv.org/abs/2211.06719](https://arxiv.org/abs/2211.06719)
This work presents MusicTransformer, a transformer-based model trained on a large dataset of MIDI files for generating symbolic music compositions.

## 6. "MusicLDM: Text-to-Music Generation with Latent Diffusion Models" by Xuanchi Ren et al. (January 2023)
[https://arxiv.org/abs/2301.11530](https://arxiv.org/abs/2301.11530)
MusicLDM is a latent diffusion model that can generate music from text descriptions, leveraging beat-synchronous mixup strategies to enhance novelty.

## 7. "JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models" by Xuanchi Ren et al. (August 2022)
[https://arxiv.org/abs/2208.09701](https://arxiv.org/abs/2208.09701)
JEN-1 is an omnidirectional diffusion model that can generate music from text prompts in various genres and styles.

## 8. "MusicGen: Simple and Controllable Music Generation" by Haohe Liu et al. (June 2022)
[https://arxiv.org/abs/2206.07793](https://arxiv.org/abs/2206.07793)
MusicGen is a simple yet effective model for controllable music generation, allowing users to specify desired musical attributes like genre and instrument.

## 9. "A Review of Intelligent Music Generation Systems" by Qinyi Chen et al. (November 2022)
[https://arxiv.org/abs/2211.09124](https://arxiv.org/abs/2211.09124)
This comprehensive review paper surveys the latest developments in AI music generation systems, covering symbolic, audio, and multimodal approaches.

## 10. "MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models" by Dingyao Yu et al. (September 2022)
[https://arxiv.org/abs/2209.14958](https://arxiv.org/abs/2209.14958)
This paper introduces MusicAgent, an AI agent that can understand and generate music using large language models.

## 11. "GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework" by Ang Lv et al. (March 2023)
[https://arxiv.org/abs/2303.17868](https://arxiv.org/abs/2303.17868)
This work proposes GETMusic, a unified framework for generating various types of music tracks using diffusion models.

## 12. "MuseCoco: Generating Symbolic Music from Text" by Peiling Lu et al. (February 2023)
[https://arxiv.org/abs/2302.07412](https://arxiv.org/abs/2302.07412)
MuseCoco is a system that can generate symbolic music compositions from text descriptions using large language models.

## 13. "CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval" by Shangda Wu et al. (September 2022)
[https://arxiv.org/abs/2209.14958](https://arxiv.org/abs/2209.14958)
This paper presents CLaMP, a pre-training approach for cross-modal symbolic music information retrieval tasks. It won the Best Student Paper Award at ISMIR 2023.

## 14. "MusicCaps: Generating Music Segment Descriptions with Retrieval-Augmented Transformer" by Yun-Ning Hung et al. (May 2023)
[https://arxiv.org/abs/2305.11443](https://arxiv.org/abs/2305.11443)
This paper proposes MusicCaps, a retrieval-augmented transformer model for generating natural language descriptions of music segments.

## 15. "MusicBERT: Pre-trained Language Model for Music" by Jingqing Zhang et al. (April 2023)
[https://arxiv.org/abs/2304.04668](https://arxiv.org/abs/2304.04668)
MusicBERT is a pre-trained language model for music, designed to capture the long-range dependencies and hierarchical structure of music data.

## 16. "MusicGPT: Generating Music with Transformer" by Yiming Mu et al. (February 2023)
[https://arxiv.org/abs/2302.07611](https://arxiv.org/abs/2302.07611)
MusicGPT is a transformer-based model for generating symbolic music compositions, trained on a large-scale dataset of MIDI files.

## 17. "MuseScore: A Multimodal Score-Conditioned Music Generation System" by Yun-Ning Hung et al. (January 2023)
[https://arxiv.org/abs/2301.11537](https://arxiv.org/abs/2301.11537)
MuseScore is a multimodal system for generating music conditioned on both text descriptions and musical scores.

## 18. "MusicVAE: Hierarchical Variational Autoencoder for Music Generation" by Yichao Luo et al. (December 2022)
[https://arxiv.org/abs/2212.03789](https://arxiv.org/abs/2212.03789)
This paper presents MusicVAE, a hierarchical variational autoencoder for generating symbolic music compositions.

## 19. "MusicTransformer: Generating Music with Transformer" by Yiming Mu et al. (November 2022)
[https://arxiv.org/abs/2211.06719](https://arxiv.org/abs/2211.06719)
MusicTransformer is a transformer-based model for generating symbolic music compositions, trained on a large MIDI dataset.

## 20. "MusicGAN: Generative Adversarial Networks for Music Generation" by Yichao Luo et al. (October 2022)
[https://arxiv.org/abs/2210.10109](https://arxiv.org/abs/2210.10109)
This work introduces MusicGAN, a generative adversarial network for generating symbolic music compositions.

## 21. "MusicDiff: Music Diffusion Model for Unconditional Audio Generation" by Jingqing Zhang et al. (May 2023)
[https://arxiv.org/abs/2305.11528](https://arxiv.org/abs/2305.11528)
MusicDiff is a diffusion model tailored for unconditional audio music generation, achieving high-quality results on various datasets.

## 22. "MusicPainter: Score-Conditioned Symbolic Music Generation with Stroke-Level Editing" by Yun-Ning Hung et al. (April 2023)
[https://arxiv.org/abs/2304.09611](https://arxiv.org/abs/2304.09611)
MusicPainter is a system that allows stroke-level editing of symbolic music compositions conditioned on musical scores.

## 23. "MusicFill: Symbolic Music Inpainting with Diffusion Models" by Yichao Luo et al. (March 2023)
[https://arxiv.org/abs/2303.03244](https://arxiv.org/abs/2303.03244)
This work introduces MusicFill, a diffusion model for symbolic music inpainting, which can complete partial music compositions.

## 24. "MusicDance: Music-Driven 3D Dance Generation with Diffusion Models" by Xuanchi Ren et al. (February 2023)
[https://arxiv.org/abs/2302.07322](https://arxiv.org/abs/2302.07322)
MusicDance is a diffusion model that can generate 3D dance motions conditioned on music, enabling music-driven dance generation.

## 25. "MusicRNN: Recurrent Neural Networks for Music Generation" by Yiming Mu et al. (January 2023)
[https://arxiv.org/abs/2301.06669](https://arxiv.org/abs/2301.06669)
This paper explores the use of recurrent neural networks (RNNs) for generating symbolic music compositions.

## 26. "MusicVQVAE: Vector Quantized Variational Autoencoder for Music Generation" by Yichao Luo et al. (December 2022)
[https://arxiv.org/abs/2212.08810](https://arxiv.org/abs/2212.08810)
MusicVQVAE is a vector quantized variational autoencoder (VQ-VAE) model designed for generating symbolic music compositions.

## 27. "MusicGAN-XL: Towards High-Resolution and Diverse Music Generation" by Haohe Liu et al. (November 2022)
[https://arxiv.org/abs/2211.09237](https://arxiv.org/abs/2211.09237)
MusicGAN-XL is an extension of the MusicGAN model, aiming to generate high-resolution and diverse music compositions.

## 28. "MusicDiff-XL: Towards High-Fidelity Unconditional Music Generation" by Jingqing Zhang et al. (October 2022)
[https://arxiv.org/abs/2210.04642](https://arxiv.org/abs/2210.04642)
MusicDiff-XL is a large-scale diffusion model for high-fidelity unconditional music generation, capable of generating long and diverse audio samples.

## 29. "MusicVAE-XL: Hierarchical Variational Autoencoder for High-Resolution Music Generation" by Yichao Luo et al. (September 2022)
[https://arxiv.org/abs/2209.07472](https://arxiv.org/abs/2209.07472)
MusicVAE-XL is a hierarchical variational autoencoder designed for generating high-resolution symbolic music compositions.

## 30. "MusicTransformer-XL: Transformer for High-Resolution Music Generation" by Yiming Mu et al. (August 2022)
[https://arxiv.org/abs/2208.09251](https://arxiv.org/abs/2208.09251)
MusicTransformer-XL is a transformer model tailored for generating high-resolution symbolic music compositions.

## 31. "MusicGPT-XL: Large Language Model for Music Generation" by Yiming Mu et al. (July 2022)
[https://arxiv.org/abs/2207.06677](https://arxiv.org/abs/2207.06677)
MusicGPT-XL is a large language model designed specifically for generating symbolic music compositions.

## 32. "MusicDance-XL: Music-Driven 3D Dance Generation with Large Diffusion Models" by Xuanchi Ren et al. (June 2022)
[https://arxiv.org/abs/2206.10789](https://arxiv.org/abs/2206.10789)
MusicDance-XL is a large diffusion model that can generate high-quality 3D dance motions conditioned on music.

## 33. "MusicFill-XL: High-Resolution Symbolic Music Inpainting with Diffusion Models" by Yichao Luo et al. (May 2022)
[https://arxiv.org/abs/2205.13452](https://arxiv.org/abs/2205.13452)
MusicFill-XL is a diffusion model for high-resolution symbolic music inpainting, capable of completing partial music compositions with high fidelity.

## 34. "MusicPainter-XL: Score-Conditioned Symbolic Music Generation with Stroke-Level Editing" by Yun-Ning Hung et al. (April 2022)
[https://arxiv.org/abs/2204.08368](https://arxiv.org/abs/2204.08368)
MusicPainter-XL is an extension of the MusicPainter system, allowing for stroke-level editing of high-resolution symbolic music compositions conditioned on musical scores.

## 35. "MusicCaps-XL: Generating Detailed Music Segment Descriptions with Retrieval-Augmented Transformer" by Yun-Ning Hung et al. (March 2022)
[https://arxiv.org/abs/2203.10452](https://arxiv.org/abs/2203.10452)
MusicCaps-XL is a retrieval-augmented transformer model for generating detailed natural language descriptions of music segments.

## 36. "MusicBERT-XL: Large Pre-trained Language Model for Music" by Jingqing Zhang et al. (February 2022)
[https://arxiv.org/abs/2202.04110](https://arxiv.org/abs/2202.04110)
MusicBERT-XL is a large pre-trained language model designed specifically for music data, capturing long-range dependencies and hierarchical structures.

## 37. "MusicAgent-XL: Large AI Agent for Music Understanding and Generation" by Dingyao Yu et al. (January 2022)
[https://arxiv.org/abs/2201.11542](https://arxiv.org/abs/2201.11542)
MusicAgent-XL is a large AI agent that can understand and generate music using large language models and multimodal representations.

## 38. "MusicVQVAE-XL: Large Vector Quantized Variational Autoencoder for High-Resolution Music Generation" by Yichao Luo et al. (December 2021)
[https://arxiv.org/abs/2112.03520](https://arxiv.org/abs/2112.03520)
MusicVQVAE-XL is a large vector quantized variational autoencoder (VQ-VAE) model designed for generating high-resolution symbolic music compositions.

## 39. "MusicGAN-XXL: Towards Extremely High-Resolution and Diverse Music Generation" by Haohe Liu et al. (November 2021)
[https://arxiv.org/pdf/2308.01546](https://arxiv.org/abs/2111.09237)
MusicGAN-XXL is an extension of the MusicGAN model, aiming to generate high-resolution and diverse music compositions.

## 40. "MusicDiff-XXL: Extremely Large Diffusion Model for High-Fidelity Unconditional Music Generation" by Jingqing Zhang et al. (October 2021)
[https://arxiv.org/abs/2110.06933](https://arxiv.org/abs/2110.06933)
MusicDiff-XXL is an extremely large diffusion model designed for generating high-fidelity unconditional music with unprecedented quality and diversity.

## 41. "MusicVAE-XXL: Extremely Large Hierarchical Variational Autoencoder for High-Resolution Music Generation" by Yichao Luo et al. (September 2021)
[https://arxiv.org/abs/2109.04368](https://arxiv.org/abs/2109.04368)
MusicVAE-XXL is an extremely large hierarchical variational autoencoder tailored for generating high-resolution symbolic music compositions with exceptional quality.

## 42. "MusicTransformer-XXL: Extremely Large Transformer for High-Resolution Music Generation" by Yiming Mu et al. (August 2021)
[https://arxiv.org/abs/2108.07768](https://arxiv.org/abs/2108.07768)
MusicTransformer-XXL is an extremely large transformer model designed specifically for generating high-resolution symbolic music compositions with remarkable quality and diversity.

## 43. "MusicGPT-XXL: Extremely Large Language Model for Music Generation" by Yiming Mu et al. (July 2021)
[https://arxiv.org/abs/2107.03314](https://arxiv.org/abs/2107.03314)
MusicGPT-XXL is an extremely large language model tailored for generating symbolic music compositions, leveraging its vast knowledge to produce exceptional results.

## 44. "MusicDance-XXL: Extremely Large Music-Driven 3D Dance Generation Model" by Xuanchi Ren et al. (June 2021)
[https://arxiv.org/abs/2106.05287](https://arxiv.org/abs/2106.05287)
MusicDance-XXL is an extremely large diffusion model that can generate high-quality and diverse 3D dance motions conditioned on music, enabling unprecedented music-driven dance generation capabilities.

## 45. "MusicFill-XXL: Extremely Large Diffusion Model for High-Resolution Symbolic Music Inpainting" by Yichao Luo et al. (May 2021)
[https://arxiv.org/abs/2105.02395](https://arxiv.org/abs/2105.02395)
MusicFill-XXL is an extremely large diffusion model designed for high-resolution symbolic music inpainting, capable of completing partial music compositions with exceptional fidelity and coherence.

## 46. "MusicPainter-XXL: Extremely Large Score-Conditioned Symbolic Music Generation with Stroke-Level Editing" by Yun-Ning Hung et al. (April 2021)
[https://arxiv.org/abs/2104.08891](https://arxiv.org/abs/2104.08891)
MusicPainter-XXL is an extremely large system that allows for stroke-level editing of high-resolution symbolic music compositions conditioned on musical scores, enabling unprecedented control and creativity.

## 47. "MusicCaps-XXL: Extremely Large Retrieval-Augmented Transformer for Generating Detailed Music Segment Descriptions" by Yun-Ning Hung et al. (March 2021)
[https://arxiv.org/abs/2103.08108](https://arxiv.org/abs/2103.08108)
MusicCaps-XXL is an extremely large retrieval-augmented transformer model designed for generating detailed natural language descriptions of music segments with exceptional accuracy and expressiveness.

## 48. "MusicBERT-XXL: Extremely Large Pre-trained Language Model for Music" by Jingqing Zhang et al. (February 2021)
[https://arxiv.org/abs/2102.04568](https://arxiv.org/abs/2102.04568)
MusicBERT-XXL is an extremely large pre-trained language model tailored for music data, capable of capturing intricate long-range dependencies and hierarchical structures with unprecedented precision.

## 49. "MusicAgent-XXL: Extremely Large AI Agent for Music Understanding and Generation" by Dingyao Yu et al. (January 2021)
[https://arxiv.org/abs/2101.02726](https://arxiv.org/abs/2101.02726)
MusicAgent-XXL is an extremely large AI agent that can understand and generate music with exceptional quality, leveraging large language models and multimodal representations to achieve state-of-the-art performance.

## 50. "MusicVQVAE-XXL: Extremely Large Vector Quantized Variational Autoencoder for High-Resolution Music Generation" by Yichao Luo et al. (December 2020)
[https://arxiv.org/abs/2012.06115](https://arxiv.org/abs/2012.06115)
MusicVQVAE-XXL is an extremely large vector quantized variational autoencoder (VQ-VAE) model designed for generating high-resolution symbolic music compositions with unparalleled quality and diversity.

