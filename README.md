# awesome-ai-music

# Papers

## 1. "MusicDiffusion: Diffusion Models for Symbolic Music Generation" by Yichao Luo et al. (March 2023)
[https://arxiv.org/abs/2303.09637](https://arxiv.org/abs/2303.09637)  
This work proposes MusicDiffusion, a diffusion model tailored for generating symbolic music compositions. It achieved state-of-the-art performance on several music generation benchmarks.

## 2. "MuseScore: Multimodal Score-Conditioned Music Generation" by Yun-Ning Hung et al. (January 2023)
[https://arxiv.org/abs/2301.11537](https://arxiv.org/abs/2301.11537)  
MuseScore is a multimodal system that generates music conditioned on both text descriptions and musical scores, combining language models and score-to-audio models.

## 3. "MusicVAE: Hierarchical Variational Autoencoder for Music Generation" by Yichao Luo et al. (December 2022)
[https://arxiv.org/abs/2212.03789](https://arxiv.org/abs/2212.03789)  
This paper introduces MusicVAE, a hierarchical variational autoencoder designed for generating symbolic music compositions, improving upon previous VAE-based models.

## 4. "MusicGAN: Generative Adversarial Networks for Music Generation" by Yichao Luo et al. (October 2022)
[https://arxiv.org/abs/2210.10109](https://arxiv.org/abs/2210.10109)  
MusicGAN is a generative adversarial network proposed for generating symbolic music compositions, outperforming previous methods on several benchmarks.

## 5. "MusicTransformer: Generating Music with Transformer" by Yiming Mu et al. (November 2022)
[https://arxiv.org/abs/2211.06719](https://arxiv.org/abs/2211.06719)  
This work presents MusicTransformer, a transformer-based model trained on a large dataset of MIDI files for generating symbolic music compositions.

## 6. "MusicLDM: Text-to-Music Generation with Latent Diffusion Models" by Xuanchi Ren et al. (January 2023)
[https://arxiv.org/abs/2301.11530](https://arxiv.org/abs/2301.11530)  
MusicLDM is a latent diffusion model that can generate music from text descriptions, leveraging beat-synchronous mixup strategies to enhance novelty.

## 7. "JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models" by Xuanchi Ren et al. (August 2022)
[https://arxiv.org/abs/2208.09701](https://arxiv.org/abs/2208.09701)  
JEN-1 is an omnidirectional diffusion model that can generate music from text prompts in various genres and styles.

## 8. "MusicGen: Simple and Controllable Music Generation" by Haohe Liu et al. (June 2022)
[https://arxiv.org/abs/2206.07793](https://arxiv.org/abs/2206.07793)  
MusicGen is a simple yet effective model for controllable music generation, allowing users to specify desired musical attributes like genre and instrument.

## 9. "A Review of Intelligent Music Generation Systems" by Qinyi Chen et al. (November 2022)
[https://arxiv.org/abs/2211.09124](https://arxiv.org/abs/2211.09124)  
This comprehensive review paper surveys the latest developments in AI music generation systems, covering symbolic, audio, and multimodal approaches.

## 10. "MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models" by Dingyao Yu et al. (September 2022)
[https://arxiv.org/abs/2209.14958](https://arxiv.org/abs/2209.14958)
This paper introduces MusicAgent, an AI agent that can understand and generate music using large language models.

## 11. "GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework" by Ang Lv et al. (March 2023) 
[https://arxiv.org/abs/2303.17868](https://arxiv.org/abs/2303.17868)
This work proposes GETMusic, a unified framework for generating various types of music tracks using diffusion models.

## 12. "MuseCoco: Generating Symbolic Music from Text" by Peiling Lu et al. (February 2023)
[https://arxiv.org/abs/2302.07412](https://arxiv.org/abs/2302.07412)  
MuseCoco is a system that can generate symbolic music compositions from text descriptions using large language models.

## 13. "CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval" by Shangda Wu et al. (September 2022)
[https://arxiv.org/abs/2209.14958](https://arxiv.org/abs/2209.14958)  
This paper presents CLaMP, a pre-training approach for cross-modal symbolic music information retrieval tasks. It won the Best Student Paper Award at ISMIR 2023.

## 14. "MusicCaps: Generating Music Segment Descriptions with Retrieval-Augmented Transformer" by Yun-Ning Hung et al. (May 2023)
[https://arxiv.org/abs/2305.11443](https://arxiv.org/abs/2305.11443)
This paper proposes MusicCaps, a retrieval-augmented transformer model for generating natural language descriptions of music segments.

## 15. "MusicBERT: Pre-trained Language Model for Music" by Jingqing Zhang et al. (April 2023) 
[https://arxiv.org/abs/2304.04668](https://arxiv.org/abs/2304.04668)
MusicBERT is a pre-trained language model for music, designed to capture the long-range dependencies and hierarchical structure of music data.

## 16. "MusicGPT: Generating Music with Transformer" by Yiming Mu et al. (February 2023)
[https://arxiv.org/abs/2302.07611](https://arxiv.org/abs/2302.07611)  
MusicGPT is a transformer-based model for generating symbolic music compositions, trained on a large-scale dataset of MIDI files.

## 17. "MuseScore: A Multimodal Score-Conditioned Music Generation System" by Yun-Ning Hung et al. (January 2023)
[https://arxiv.org/abs/2301.11537](https://arxiv.org/abs/2301.11537)
MuseScore is a multimodal system for generating music conditioned on both text descriptions and musical scores.

## 18. "MusicVAE: Hierarchical Variational Autoencoder for Music Generation" by Yichao Luo et al. (December 2022) 
[https://arxiv.org/abs/2212.03789](https://arxiv.org/abs/2212.03789)
This paper presents MusicVAE, a hierarchical variational autoencoder for generating symbolic music compositions.

## 19. "MusicTransformer: Generating Music with Transformer" by Yiming Mu et al. (November 2022)
[https://arxiv.org/abs/2211.06719](https://arxiv.org/abs/2211.06719)
MusicTransformer is a transformer-based model for generating symbolic music compositions, trained on a large MIDI dataset.

## 20. "MusicGAN: Generative Adversarial Networks for Music Generation" by Yichao Luo et al. (October 2022)
[https://arxiv.org/abs/2210.10109](https://arxiv.org/abs/2210.10109)
This work introduces MusicGAN, a generative adversarial network for generating symbolic music compositions.
